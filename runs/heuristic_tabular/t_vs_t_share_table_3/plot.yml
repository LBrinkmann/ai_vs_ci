# alpha, networktype, reward, share_table, mode
clean: true

preprocess_args:
  combine:
    metric:
      coordination: 
        name: mean_avg_coordination
      catch: 
        name: mean_avg_catch
      diff: 
        name: mean_reward
        agent_type: ci
    ind_metric:
      coordination: 
        name: ind_coordination
      catch: 
        name: ind_catch
      diff: 
        name: reward
        agent_type: ci
    fixed:
      both: 
        fixed_mapping: true
        fixed_network: true
      neither: 
        fixed_mapping: false
        fixed_network: false
      network: 
        fixed_mapping: false
        fixed_network: true
      mapping: 
        fixed_mapping: true
        fixed_network: false
    reward_opt:
      ai_coll_ci_coll_zero_sum_001:
        alpha: 0.01
        reward: ai_coll_ci_coll_zero_sum
      ai_coll_ci_coll_zero_sum:
        alpha: 0.1
        reward: ai_coll_ci_coll_zero_sum
      ai_coll_ci_coll:
        alpha: 0.1
        reward: ai_coll_ci_coll
      ai_ind_ci_ind:
        alpha: 0.1
        reward: ai_ind_ci_ind
      ai_ind_ci_ind_zero_sum:
        alpha: 0.1
        reward: ai_ind_ci_ind_zero_sum
plot_args:
  - 
    expand: [alpha]
    selectors:
      mode: train
      # agents: mean
      # fixed: both
    grid: [fixed,reward]
    style: metric
    hue: share_table
    name: share_table_sel
  # - 
  #   selectors:
  #     mode: train
  #     agents: mean
  #     fixed: both
  #     agent_type: ci
  #     name: [stick_to_color, max_freq]
  #   grid: [reward_opt,name]
  #   hue: share_table
  #   # style: name
  #   name: share_table_actions_sel
