exec:
  python_file: aci/adversial.py
  script_name: cpu
labels:
  project: ai_vs_ci
  batch: maq_vs_heuristic
grid:
  - - params.env_args: 
        graph_args:
          graph_type: random_regular
          degree: 1
          chromatic_number: 2
        all_agents: 2
      labels.networktype: full2
    - params.env_args: 
        graph_args:
          graph_type: random_regular
          degree: 5
          chromatic_number: 6
        all_agents: 6
      labels.networktype: full6
    - params.env_args: 
        graph_args:
          graph_type: cycle
          degree: 2
        all_agents: 6
      labels.networktype: cycle62
    - params.env_args: 
        graph_args:
          graph_type: cycle
          degree: 4
        all_agents: 6
      labels.networktype: cycle64
    - params.env_args: 
        graph_args:
          graph_type: random_regular
          degree: 4
          chromatic_number: 3
        all_agents: 6
      labels.networktype: reg6_4_3
    - params.env_args: 
        graph_args:
          graph_type: random_regular
          degree: 4
          chromatic_number: 4
        all_agents: 10
      labels.networktype: reg10_4_4
  - - params.env_args.rewards_args:
        ai:
          avg_coordination: -1
          avg_catch: 1
        ci:
          ind_coordination: 1
          avg_coordination: 0
          ind_catch: 0
          avg_catch: 0
      labels.rewards: individual
    - params.env_args.rewards_args:
        ai:
          avg_coordination: -1
          avg_catch: 1
        ci:
          ind_coordination: 0
          avg_coordination: 1
          ind_catch: 0
          avg_catch: 0
      labels.rewards: collective
    - params.env_args.rewards_args:
        ai:
          avg_coordination: -1
          avg_catch: 1
        ci:
          ind_coordination: 0
          avg_coordination: 1
          ind_catch: -1
          avg_catch: 0
      labels.rewards: ind_zero_sum
    - params.env_args.rewards_args:
        ai:
          avg_coordination: -1
          avg_catch: 1
        ci:
          ind_coordination: 1
          avg_coordination: 0
          ind_catch: 0
          avg_catch: -1
      labels.rewards: col_zero_sum
  - - params.agent_types.ci.controller_args.model_args:
        net_type: rnn
        hidden_size: 10
      labels.net_type: rnn
    - params.agent_types.ci.controller_args.model_args:
        net_type: linear
      labels.net_type: linear
  - params.agent_types.ci.controller_args.model_args.multi_type: [shared_weights, individual_weights]
    labels.multi_type: [shared_weights, individual_weights]
  - params.agent_types.ci.controller_args.opt_args.lr: [0.1, 0.01, 0.001]
    labels.lr: [0.1, 0.01, 0.001]
params:
  agent_types:
    ci:
      selector_args:
        eps_start: 0.20
        eps_end: 0.20
        eps_decay: 2000
      controller_args:
        gamma: 0.8
        cache_size: 1
        model_args: {}
          # net_type: rnn
          # hidden_size: 10
          # multi_type: shared_weights
          # # multi_type: individual_weights
        opt_args:
          lr: 0.001
      controller_class: maq
    ai:
      selector_args:
        eps_start: 0.20
        eps_end: 0.20
        eps_decay: 2000
      replay_memory: null
      controller_args: 
        heuristic_name: hai1
        agent_args: {}
      controller_class: heuristic
  train_args:
    eval_period: 10
    num_episodes: 10000
    # num_episodes: 1000
  writer_args:
    periods:
      video: 2500
      final: 10
      trace: 100
      # individual_trace: 100
      table: 2500
  env_class: adversial_graph_coloring
  env_args:
    ai_obs_mode: agents_matrix
    graph_args:
      graph_type: random_regular
      degree: 3
      chromatic_number: 3
    all_agents: 10
    fixed_agents: 0
    max_steps: 50
    fixed_length: true
    fixed_pos: true
    fixed_network: true
    rewards_args:
      ai:
        avg_coordination: -1
        avg_catch: 1
      ci:
        ind_coordination: 0.5
        avg_coordination: 0.5
        ind_catch: -0.5
        avg_catch: -0.5
