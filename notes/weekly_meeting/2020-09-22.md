# Results

## Graph neural network

![](../../runs/gnn/test1/plot/mean.png)

* seems to perform worse then the other architectures so far
* not really surprisingly
* expect benefits only for predicition further into the future

#### Discussion

## CI /AI Asymmetry

### Asymmetry in layers

![](../../runs/attention/asymmetric_layer/plot/mean.png)

#### Discussion

### Asymmetry in hidden dimensions

![](../../runs/attention/asymmetric_hidden/plot/mean.png)

#### Discussion
* dashed line: coordination always above catch, but in uper right (beginning)
* upper right, learning rate: lower learning rate is better

### Asymmetry in learning rate

![](../../runs/attention/asymmetric_lr/plot/mean.png)

#### Discussion

## CI Secret

![](../../runs/seed/test1/plot/mean.png)

#### Discussion

* having a feedback to the agents how well they were performing in the previous round
* idea: seed disambitious between mixed strategies
    * feeding into last layer
    * hard coded strategy how to process the secret


# Next steps
* deep dive CI secret
    * asymmetric learning rates
    * without on / off
    * code review
    * alternative architectures?
* cheap communication
    * write tests for environment
    * run on / off
* noisy weight sharing

# TODO
* feedback how well they were performing in the previous round
    * feature to each of the neighbors if they were catched - implemented and tested
    * global feature on how many where catched / coordinated in previous round - implemented and tested
* mixed strategy
    * new seed each round
    * feeding into last layer - implemented
    * taking outer product of input and secret - implemented
    * hard coded strategy how to process the secret
* further investigation seed 
    * interaction with learning rate / hidden size, situations where CI is challenged
* asymmetry
    * more learning rates - running
    * more hidden sizes - running
    * interaction asymmetric hidden size, asymmetric learning rate

# Runs
1. feedback
controls
* learning rate / architecture (2x symmetric + 2x CI challenged)

effects 
* no catch
* catch of neighbor
* self catch at control
* global catch at control - cat
* global catch and coordination at control - cat

-> done for symmetric

2. control position and type (secret)
controls
* learning rate / architecture (2x symmetric + 2x CI challenged)

effects
* norm outer / cat
* position (3x)
* size (3x)

-> not done

3. fill up lr grid

-> done

4. interaction
hidden_size:
ai: 100
ci: 10, 20, 100

lr:
ai: 0.001
ci: 0.0001 - 0.01

-> not done