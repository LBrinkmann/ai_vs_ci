# Results

## Graph neural network

![](../../runs/gnn/test1/plot/mean.png)

* seems to perform worse then the other architectures so far
* not really surprisingly
* expect benefits only for predicition further into the future

#### Discussion

## CI /AI Asymmetry

### Asymmetry in layers

![](../../runs/attention/asymmetric_layer/plot/mean.png)

#### Discussion

### Asymmetry in hidden dimensions

![](../../runs/attention/asymmetric_hidden/plot/mean.png)

#### Discussion
* dashed line: coordination always above catch, but in uper right (beginning)
* upper right, learning rate: lower learning rate is better

### Asymmetry in learning rate

![](../../runs/attention/asymmetric_lr/plot/mean.png)

#### Discussion

## CI Secret

![](../../runs/seed/test1/plot/mean.png)

#### Discussion

* having a feedback to the agents how well they were performing in the previous round
* idea: seed disambitious between mixed strategies
    * feeding into last layer
    * hard coded strategy how to process the secret


# Next steps
* deep dive CI secret
    * asymmetric learning rates
    * without on / off
    * code review
    * alternative architectures?
* cheap communication
    * write tests for environment
    * run on / off
* noisy weight sharing

# TODO
* feedback how well they were performing in the previous round
    * feature to each of the neighbors if they were catched
    * global feature on how many where catched / coordinated in previous round
* mixed strategy
    * new seed each round
    * feeding into last layer
    * taking outer product of input and secret
    * hard coded strategy how to process the secret
* further investigation seed 
    * interaction with learning rate / hidden size, situations where CI is challenged
* asymmetry
    * more learning rates - running
    * more hidden sizes - running
    * interaction asymmetric hidden size, asymmetric learning rate

