# TabularQ learning 

## the reward matters a lot


![](../../runs/heuristic_tabular/t_vs_t_share_table_2/plot/share_table_sel.png)

![](../../runs/heuristic_tabular/t_vs_t_share_table_2/plot/share_table_actions_sel.png)


TODO: effect of randomizing network and agent position

# Approximate Q learning 

* memory replay
* batch_learning

![](../../runs/madqn/test3/plot/mean.png)

![](../../runs/madqn/test3/plot/actions_mean.png)

oscillations because of target update every 1000 step?

![](../../runs/madqn/test3/plot/agents.png)